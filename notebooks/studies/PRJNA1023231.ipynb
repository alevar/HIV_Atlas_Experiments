{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE244468\n",
    "project page: https://www.ncbi.nlm.nih.gov/bioproject/PRJNA1023231\n",
    "study: https://www.nature.com/articles/s41594-024-01468-3#Sec2\n",
    "biosample_results: https://www.ncbi.nlm.nih.gov/biosample?LinkName=bioproject_biosample_all&from_uid=1023231"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import requests\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pysradb import SRAweb\n",
    "\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path.cwd().parent.parent.parent / 'HIV_Atlas_Creation' / 'data'\n",
    "\n",
    "sequence_dir = data_dir / 'sequences'\n",
    "assert sequence_dir.exists(), f\"sequence_dir does not exist: {sequence_dir}\"\n",
    "\n",
    "annotation_dir = data_dir / 'annotation'\n",
    "assert annotation_dir.exists(), f\"annotation_dir does not exist: {annotation_dir}\"\n",
    "\n",
    "base_dir = Path.cwd().parent.parent\n",
    "\n",
    "soft_dir = base_dir / 'soft'\n",
    "\n",
    "prj_id = 'PRJNA1023231'\n",
    "\n",
    "outdir = base_dir / 'results' / prj_id\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "prj_data_dir = outdir / 'data'\n",
    "prj_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "prj_fastq_dir = prj_data_dir / 'fastq'\n",
    "prj_fastq_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "prj_aln_dir = outdir / 'alignment'\n",
    "prj_aln_dir.mkdir(parents=True, exist_ok=True)\n",
    "prj_assembly_dir = outdir / 'assembly'\n",
    "prj_assembly_dir.mkdir(parents=True, exist_ok=True)\n",
    "prj_quant_dir = outdir / 'quantification'\n",
    "prj_quant_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "hisat_idx_basename = base_dir / 'data' / 'NL43/reference'\n",
    "reference_fasta_fname = base_dir / 'data' / 'NL43/reference.fasta'\n",
    "reference_gtf_fname = base_dir / 'data' / 'NL43/reference.gtf'\n",
    "t2g_fname = base_dir / 'data' / 'NL43/reference.t2g.tsv'\n",
    "hiv_accid = \"AF324493.2\"\n",
    "\n",
    "biosample_results_fname = prj_data_dir / 'metadata/biosample_results.tsv'\n",
    "\n",
    "sashimi_bin = \"sashimi.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "sys.path.insert(0, str(soft_dir / \"genomic_scripts\"))\n",
    "%aimport definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>biosample</th>\n",
       "      <th>sra</th>\n",
       "      <th>geo</th>\n",
       "      <th>run_accession</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SupT1 mock, RiboSeq, cyclo, 0hpi, rep1</td>\n",
       "      <td>SAMN37652043</td>\n",
       "      <td>SRS19047042</td>\n",
       "      <td>GSM7816472</td>\n",
       "      <td>SRR26261550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SupT1 mock, RiboSeq, cyclo, 0hpi, rep2</td>\n",
       "      <td>SAMN37652042</td>\n",
       "      <td>SRS19047046</td>\n",
       "      <td>GSM7816473</td>\n",
       "      <td>SRR26261541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SupT1 infected, RiboSeq, cyclo, 8hpi, rep1</td>\n",
       "      <td>SAMN37652041</td>\n",
       "      <td>SRS19047047</td>\n",
       "      <td>GSM7816474</td>\n",
       "      <td>SRR26261540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SupT1 infected, RiboSeq, cyclo, 8hpi, rep2</td>\n",
       "      <td>SAMN37652040</td>\n",
       "      <td>SRS19047048</td>\n",
       "      <td>GSM7816475</td>\n",
       "      <td>SRR26261539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SupT1 infected, RiboSeq, cyclo, 16hpi, rep1</td>\n",
       "      <td>SAMN37652039</td>\n",
       "      <td>SRS19048965</td>\n",
       "      <td>GSM7816476</td>\n",
       "      <td>SRR26261538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sample     biosample          sra  \\\n",
       "0       SupT1 mock, RiboSeq, cyclo, 0hpi, rep1  SAMN37652043  SRS19047042   \n",
       "1       SupT1 mock, RiboSeq, cyclo, 0hpi, rep2  SAMN37652042  SRS19047046   \n",
       "2   SupT1 infected, RiboSeq, cyclo, 8hpi, rep1  SAMN37652041  SRS19047047   \n",
       "3   SupT1 infected, RiboSeq, cyclo, 8hpi, rep2  SAMN37652040  SRS19047048   \n",
       "4  SupT1 infected, RiboSeq, cyclo, 16hpi, rep1  SAMN37652039  SRS19048965   \n",
       "\n",
       "          geo run_accession  \n",
       "0  GSM7816472   SRR26261550  \n",
       "1  GSM7816473   SRR26261541  \n",
       "2  GSM7816474   SRR26261540  \n",
       "3  GSM7816475   SRR26261539  \n",
       "4  GSM7816476   SRR26261538  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load metadata\n",
    "metadata_df = pd.read_csv(biosample_results_fname, sep='\\t')\n",
    "\n",
    "db = SRAweb()\n",
    "batch_results = db.sra_metadata(metadata_df[\"sra\"].tolist(), detailed=True)\n",
    "metadata_df = metadata_df.merge(batch_results[[\"run_accession\",\"sample_accession\"]],left_on=\"sra\",right_on=\"sample_accession\",how=\"left\")\n",
    "metadata_df = metadata_df.drop(columns=[\"sample_accession\"])\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>biosample</th>\n",
       "      <th>sra</th>\n",
       "      <th>geo</th>\n",
       "      <th>run_accession</th>\n",
       "      <th>sequencing_cat</th>\n",
       "      <th>treatment_cat</th>\n",
       "      <th>timepoint_cat</th>\n",
       "      <th>rep_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SupT1 mock, RiboSeq, cyclo, 0hpi, rep1</td>\n",
       "      <td>SAMN37652043</td>\n",
       "      <td>SRS19047042</td>\n",
       "      <td>GSM7816472</td>\n",
       "      <td>SRR26261550</td>\n",
       "      <td>RiboSeq</td>\n",
       "      <td>cyclo</td>\n",
       "      <td>0hpi</td>\n",
       "      <td>rep1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SupT1 mock, RiboSeq, cyclo, 0hpi, rep2</td>\n",
       "      <td>SAMN37652042</td>\n",
       "      <td>SRS19047046</td>\n",
       "      <td>GSM7816473</td>\n",
       "      <td>SRR26261541</td>\n",
       "      <td>RiboSeq</td>\n",
       "      <td>cyclo</td>\n",
       "      <td>0hpi</td>\n",
       "      <td>rep2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SupT1 infected, RiboSeq, cyclo, 8hpi, rep1</td>\n",
       "      <td>SAMN37652041</td>\n",
       "      <td>SRS19047047</td>\n",
       "      <td>GSM7816474</td>\n",
       "      <td>SRR26261540</td>\n",
       "      <td>RiboSeq</td>\n",
       "      <td>cyclo</td>\n",
       "      <td>8hpi</td>\n",
       "      <td>rep1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SupT1 infected, RiboSeq, cyclo, 8hpi, rep2</td>\n",
       "      <td>SAMN37652040</td>\n",
       "      <td>SRS19047048</td>\n",
       "      <td>GSM7816475</td>\n",
       "      <td>SRR26261539</td>\n",
       "      <td>RiboSeq</td>\n",
       "      <td>cyclo</td>\n",
       "      <td>8hpi</td>\n",
       "      <td>rep2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SupT1 infected, RiboSeq, cyclo, 16hpi, rep1</td>\n",
       "      <td>SAMN37652039</td>\n",
       "      <td>SRS19048965</td>\n",
       "      <td>GSM7816476</td>\n",
       "      <td>SRR26261538</td>\n",
       "      <td>RiboSeq</td>\n",
       "      <td>cyclo</td>\n",
       "      <td>16hpi</td>\n",
       "      <td>rep1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sample     biosample          sra  \\\n",
       "0       SupT1 mock, RiboSeq, cyclo, 0hpi, rep1  SAMN37652043  SRS19047042   \n",
       "1       SupT1 mock, RiboSeq, cyclo, 0hpi, rep2  SAMN37652042  SRS19047046   \n",
       "2   SupT1 infected, RiboSeq, cyclo, 8hpi, rep1  SAMN37652041  SRS19047047   \n",
       "3   SupT1 infected, RiboSeq, cyclo, 8hpi, rep2  SAMN37652040  SRS19047048   \n",
       "4  SupT1 infected, RiboSeq, cyclo, 16hpi, rep1  SAMN37652039  SRS19048965   \n",
       "\n",
       "          geo run_accession sequencing_cat treatment_cat timepoint_cat rep_cat  \n",
       "0  GSM7816472   SRR26261550        RiboSeq         cyclo          0hpi    rep1  \n",
       "1  GSM7816473   SRR26261541        RiboSeq         cyclo          0hpi    rep2  \n",
       "2  GSM7816474   SRR26261540        RiboSeq         cyclo          8hpi    rep1  \n",
       "3  GSM7816475   SRR26261539        RiboSeq         cyclo          8hpi    rep2  \n",
       "4  GSM7816476   SRR26261538        RiboSeq         cyclo         16hpi    rep1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract column with experimental information\n",
    "metadata_df[\"sequencing_cat\"] = metadata_df[\"sample\"].str.split(\",\",n=2,expand=True)[1].str.strip()\n",
    "metadata_df[\"treatment_cat\"] = np.where(metadata_df[\"sequencing_cat\"] == \"RNASeq\",\n",
    "                                            \"-\",\n",
    "                                            metadata_df[\"sample\"].str.split(\",\",expand=True)[2].str.strip()\n",
    "                                        )\n",
    "metadata_df[\"timepoint_cat\"] = np.where(metadata_df[\"sequencing_cat\"] == \"RNASeq\",\n",
    "                                            metadata_df[\"sample\"].str.split(\",\",expand=True)[2].str.strip(),\n",
    "                                            metadata_df[\"sample\"].str.split(\",\",expand=True)[3].str.strip()\n",
    "                                        )\n",
    "metadata_df[\"rep_cat\"] = np.where(metadata_df[\"sequencing_cat\"] == \"RNASeq\",\n",
    "                                    metadata_df[\"sample\"].str.split(\",\",expand=True)[3].str.strip(),\n",
    "                                    metadata_df[\"sample\"].str.split(\",\",expand=True)[4].str.strip()\n",
    "                                )\n",
    "metadata_df.to_csv(prj_data_dir / 'metadata/metadata.tsv',sep=\"\\t\",index=False)\n",
    "\n",
    "pheno_df = metadata_df[[\"run_accession\",\"sequencing_cat\",\"treatment_cat\",\"timepoint_cat\",\"rep_cat\"]]\n",
    "pheno_df.columns = [\"id\",\"sequencing_cat\",\"treatment_cat\",\"timepoint_cat\",\"rep_cat\"]\n",
    "pheno_df.to_csv(prj_data_dir / 'metadata/pheno.tsv',sep=\"\\t\",index=False)\n",
    "\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>biosample</th>\n",
       "      <th>sra</th>\n",
       "      <th>geo</th>\n",
       "      <th>run_accession</th>\n",
       "      <th>sequencing_cat</th>\n",
       "      <th>treatment_cat</th>\n",
       "      <th>timepoint_cat</th>\n",
       "      <th>rep_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SupT1 mock, RiboSeq, cyclo, 0hpi, rep1</td>\n",
       "      <td>SAMN37652043</td>\n",
       "      <td>SRS19047042</td>\n",
       "      <td>GSM7816472</td>\n",
       "      <td>SRR26261550</td>\n",
       "      <td>RiboSeq</td>\n",
       "      <td>cyclo</td>\n",
       "      <td>0hpi</td>\n",
       "      <td>rep1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SupT1 mock, RiboSeq, cyclo, 0hpi, rep2</td>\n",
       "      <td>SAMN37652042</td>\n",
       "      <td>SRS19047046</td>\n",
       "      <td>GSM7816473</td>\n",
       "      <td>SRR26261541</td>\n",
       "      <td>RiboSeq</td>\n",
       "      <td>cyclo</td>\n",
       "      <td>0hpi</td>\n",
       "      <td>rep2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SupT1 infected, RiboSeq, cyclo, 8hpi, rep1</td>\n",
       "      <td>SAMN37652041</td>\n",
       "      <td>SRS19047047</td>\n",
       "      <td>GSM7816474</td>\n",
       "      <td>SRR26261540</td>\n",
       "      <td>RiboSeq</td>\n",
       "      <td>cyclo</td>\n",
       "      <td>8hpi</td>\n",
       "      <td>rep1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SupT1 infected, RiboSeq, cyclo, 8hpi, rep2</td>\n",
       "      <td>SAMN37652040</td>\n",
       "      <td>SRS19047048</td>\n",
       "      <td>GSM7816475</td>\n",
       "      <td>SRR26261539</td>\n",
       "      <td>RiboSeq</td>\n",
       "      <td>cyclo</td>\n",
       "      <td>8hpi</td>\n",
       "      <td>rep2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SupT1 infected, RiboSeq, cyclo, 16hpi, rep1</td>\n",
       "      <td>SAMN37652039</td>\n",
       "      <td>SRS19048965</td>\n",
       "      <td>GSM7816476</td>\n",
       "      <td>SRR26261538</td>\n",
       "      <td>RiboSeq</td>\n",
       "      <td>cyclo</td>\n",
       "      <td>16hpi</td>\n",
       "      <td>rep1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sample     biosample          sra  \\\n",
       "0       SupT1 mock, RiboSeq, cyclo, 0hpi, rep1  SAMN37652043  SRS19047042   \n",
       "1       SupT1 mock, RiboSeq, cyclo, 0hpi, rep2  SAMN37652042  SRS19047046   \n",
       "2   SupT1 infected, RiboSeq, cyclo, 8hpi, rep1  SAMN37652041  SRS19047047   \n",
       "3   SupT1 infected, RiboSeq, cyclo, 8hpi, rep2  SAMN37652040  SRS19047048   \n",
       "4  SupT1 infected, RiboSeq, cyclo, 16hpi, rep1  SAMN37652039  SRS19048965   \n",
       "\n",
       "          geo run_accession sequencing_cat treatment_cat timepoint_cat rep_cat  \n",
       "0  GSM7816472   SRR26261550        RiboSeq         cyclo          0hpi    rep1  \n",
       "1  GSM7816473   SRR26261541        RiboSeq         cyclo          0hpi    rep2  \n",
       "2  GSM7816474   SRR26261540        RiboSeq         cyclo          8hpi    rep1  \n",
       "3  GSM7816475   SRR26261539        RiboSeq         cyclo          8hpi    rep2  \n",
       "4  GSM7816476   SRR26261538        RiboSeq         cyclo         16hpi    rep1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pheno_fname = prj_data_dir / 'metadata/pheno.tsv'\n",
    "metadata_df = pd.read_csv(prj_data_dir / 'metadata/metadata.tsv', sep='\\t')\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have the following features: sequencing_cat\ttreatment_cat\ttimepoint_cat\n",
    "# need to setup groups of samples to compare\n",
    "# instead of hierarchies - we'll just slice the dataframe and give it names and store in dict\n",
    "cmp_groups = {\n",
    "    (\"RiboSeq\",\"RNASeq\"):{\n",
    "        \"RiboSeq\":metadata_df[(metadata_df[\"sequencing_cat\"] == \"RiboSeq\")][\"run_accession\"].tolist(),\n",
    "        \"RNASeq\":metadata_df[(metadata_df[\"sequencing_cat\"] == \"RNASeq\")][\"run_accession\"].tolist()\n",
    "    },\n",
    "    (\"cyclo\",\"harr\"): {\n",
    "        \"cyclo\":metadata_df[(metadata_df[\"treatment_cat\"] == \"cyclo\")][\"run_accession\"].tolist(),\n",
    "        \"harr\":metadata_df[(metadata_df[\"treatment_cat\"] == \"harr\")][\"run_accession\"].tolist()\n",
    "    },\n",
    "    (\"0\",\"8\",\"16\",\"24\"): {\n",
    "        \"0\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"0hpi\")][\"run_accession\"].tolist(),\n",
    "        \"8\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"8hpi\")][\"run_accession\"].tolist(),\n",
    "        \"16\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"16hpi\")][\"run_accession\"].tolist(),\n",
    "        \"24\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"24hpi\")][\"run_accession\"].tolist()\n",
    "    },\n",
    "    (\"RNASeq_0\",\"RNASeq_8\",\"RNASeq_16\",\"RNASeq_24\"): {\n",
    "        \"RNASeq_0\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"0hpi\") & (metadata_df[\"sequencing_cat\"]==\"RNASeq\")][\"run_accession\"].tolist(),\n",
    "        \"RNASeq_8\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"8hpi\") & (metadata_df[\"sequencing_cat\"]==\"RNASeq\")][\"run_accession\"].tolist(),\n",
    "        \"RNASeq_16\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"16hpi\") & (metadata_df[\"sequencing_cat\"]==\"RNASeq\")][\"run_accession\"].tolist(),\n",
    "        \"RNASeq_24\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"24hpi\") & (metadata_df[\"sequencing_cat\"]==\"RNASeq\")][\"run_accession\"].tolist()\n",
    "    },\n",
    "    (\"RiboSeq_0\",\"RiboSeq_8\",\"RiboSeq_16\",\"RiboSeq_24\"): {\n",
    "        \"RiboSeq_0\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"0hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\")][\"run_accession\"].tolist(),\n",
    "        \"RiboSeq_8\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"8hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\")][\"run_accession\"].tolist(),\n",
    "        \"RiboSeq_16\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"16hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\")][\"run_accession\"].tolist(),\n",
    "        \"RiboSeq_24\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"24hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\")][\"run_accession\"].tolist()\n",
    "    },\n",
    "    (\"RiboSeq_cyclo_0\",\"RiboSeq_cyclo_8\",\"RiboSeq_cyclo_16\",\"RiboSeq_cyclo_24\"): {\n",
    "        \"RiboSeq_cyclo_0\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"0hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\") & (metadata_df[\"treatment_cat\"]==\"cyclo\")][\"run_accession\"].tolist(),\n",
    "        \"RiboSeq_cyclo_8\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"8hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\") & (metadata_df[\"treatment_cat\"]==\"cyclo\")][\"run_accession\"].tolist(),\n",
    "        \"RiboSeq_cyclo_16\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"16hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\") & (metadata_df[\"treatment_cat\"]==\"cyclo\")][\"run_accession\"].tolist(),\n",
    "        \"RiboSeq_cyclo_24\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"24hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\") & (metadata_df[\"treatment_cat\"]==\"cyclo\")][\"run_accession\"].tolist()\n",
    "    },\n",
    "    (\"RiboSeq_harr_0\",\"RiboSeq_harr_8\",\"RiboSeq_harr_16\",\"RiboSeq_harr_24\"): {\n",
    "        \"RiboSeq_harr_0\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"0hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\") & (metadata_df[\"treatment_cat\"]==\"harr\")][\"run_accession\"].tolist(),\n",
    "        \"RiboSeq_harr_8\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"8hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\") & (metadata_df[\"treatment_cat\"]==\"harr\")][\"run_accession\"].tolist(),\n",
    "        \"RiboSeq_harr_16\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"16hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\") & (metadata_df[\"treatment_cat\"]==\"harr\")][\"run_accession\"].tolist(),\n",
    "        \"RiboSeq_harr_24\":metadata_df[(metadata_df[\"timepoint_cat\"] == \"24hpi\") & (metadata_df[\"sequencing_cat\"]==\"RiboSeq\") & (metadata_df[\"treatment_cat\"]==\"harr\")][\"run_accession\"].tolist()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_lst_fname = prj_fastq_dir / 'cmd_lst.txt'\n",
    "with open(cmd_lst_fname, 'w') as outFP:\n",
    "    for run_id in metadata_df[\"run_accession\"].tolist():\n",
    "        os.makedirs(prj_fastq_dir, exist_ok=True)\n",
    "        cmd_dump = f\"fasterq-dump {run_id} --outdir {prj_fastq_dir} --split-3\"\n",
    "        outFP.write(f\"{cmd_dump}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align samples with hisat\n",
    "cmd_lst_fname = prj_aln_dir / 'cmd_lst.txt'\n",
    "with open(cmd_lst_fname, 'w') as outFP:\n",
    "    for run_id in metadata_df[\"run_accession\"].tolist():\n",
    "        cmd = f\"hisat2 -p 25 --score-min L,0,-2 --mp 2,2 -x {hisat_idx_basename} -U {prj_fastq_dir}/{run_id}.fastq -S {prj_aln_dir}/{run_id}.sam\"\n",
    "        outFP.write(f\"{cmd}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort reads by position\n",
    "cmd_lst_fname = prj_aln_dir / 'cmd_lst.sort.txt'\n",
    "with open(cmd_lst_fname, 'w') as outFP:\n",
    "    for run_id in metadata_df[\"run_accession\"].tolist():\n",
    "        cmd = f\"samtools sort -@ 25 -o {prj_aln_dir}/{run_id}.sorted.bam {prj_aln_dir}/{run_id}.sam && samtools index {prj_aln_dir}/{run_id}.sorted.bam\"\n",
    "        outFP.write(f\"{cmd}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract viral reads\n",
    "cmd_lst_fname = prj_aln_dir / 'cmd_lst.extract.txt'\n",
    "with open(cmd_lst_fname, 'w') as outFP:\n",
    "    for run_id in metadata_df[\"run_accession\"].tolist():\n",
    "        cmd = f\"samtools view -h {prj_aln_dir}/{run_id}.sorted.bam {hiv_accid} | samtools sort -o {prj_aln_dir}/{run_id}.{hiv_accid}.sorted.bam - && samtools index {prj_aln_dir}/{run_id}.{hiv_accid}.sorted.bam\"\n",
    "        outFP.write(f\"{cmd}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble with stringtie\n",
    "cmd_lst_fname = prj_assembly_dir / 'cmd_lst.txt'\n",
    "with open(cmd_lst_fname, 'w') as outFP:\n",
    "    for run_id in metadata_df[\"run_accession\"].tolist():\n",
    "        cmd = f\"stringtie -p 64 -G {reference_gtf_fname} -o {prj_assembly_dir}/{run_id}.gtf {prj_aln_dir}/{run_id}.sorted.bam\"\n",
    "        outFP.write(f\"{cmd}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare tiebrush and gffcompare aggreagations\n",
    "tb_cmd_lst_fname = prj_aln_dir / 'tiebrush_cmd_lst.txt'\n",
    "tiecov_cmd_lst_fname = prj_aln_dir / 'tiecov_cmd_lst.txt'\n",
    "gffcmp_cmd_lst_fname = prj_assembly_dir / 'gffcmp_cmd_lst.txt'\n",
    "with open(tb_cmd_lst_fname, 'w') as tb_cmd_outFP, open(gffcmp_cmd_lst_fname, 'w') as gffcmp_cmd_outFP, open(tiecov_cmd_lst_fname, 'w') as tiecov_cmd_outFP:\n",
    "    for grp_name, grp_data in cmp_groups.items():\n",
    "        all_name = \".\".join(grp_name)\n",
    "        # tb\n",
    "        all_bam_fname = prj_aln_dir / f'{all_name}.{hiv_accid}.bam'\n",
    "        all_bam_lst_fname = prj_aln_dir / f'{all_name}.lst'\n",
    "        # tiecov\n",
    "        all_junctions_fname = prj_aln_dir / f'{all_name}.{hiv_accid}.junctions.bed'\n",
    "        all_cov_fname = prj_aln_dir / f'{all_name}.{hiv_accid}.coverage.bedgraph'\n",
    "        # gffcompare\n",
    "        all_gtf_fname = prj_assembly_dir / f'{all_name}.gtf'\n",
    "        all_gtf_lst_fname = prj_assembly_dir / f'{all_name}.lst'\n",
    "        with open(all_bam_lst_fname, 'w') as all_outFP, open(all_gtf_lst_fname, 'w') as all_gtf_outFP:\n",
    "            for exp_name, run_ids in grp_data.items():\n",
    "                exp_bam_lst_fname = prj_aln_dir / f'{exp_name}.lst'\n",
    "                exp_gtf_lst_fname = prj_assembly_dir / f'{exp_name}.lst'\n",
    "                # tb\n",
    "                exp_bam_fname = prj_aln_dir / f'{exp_name}.{hiv_accid}.bam'\n",
    "                # tiecov\n",
    "                exp_junctions_fname = prj_aln_dir / f'{exp_name}.{hiv_accid}.junctions.bed'\n",
    "                exp_cov_fname = prj_aln_dir / f'{exp_name}.{hiv_accid}.coverage.bedgraph'\n",
    "                # gffcompare\n",
    "                exp_gtf_fname = prj_assembly_dir / f'{exp_name}.gtf'\n",
    "                all_outFP.write(f\"{exp_bam_fname}\\n\")\n",
    "                all_gtf_outFP.write(f\"{exp_gtf_fname}\\n\")\n",
    "                with open(exp_bam_lst_fname, 'w') as exp_outFP, open(exp_gtf_lst_fname, 'w') as exp_gtf_outFP:\n",
    "                    for run_id in run_ids:\n",
    "                        exp_outFP.write(f\"{prj_aln_dir}/{run_id}.{hiv_accid}.sorted.bam\\n\")\n",
    "                        exp_gtf_outFP.write(f\"{prj_assembly_dir}/{run_id}.gtf\\n\")\n",
    "                # tb\n",
    "                tb_cmd = f\"tiebrush -o {exp_bam_fname} {exp_bam_lst_fname}\"\n",
    "                tb_cmd_outFP.write(f\"{tb_cmd}\\n\")\n",
    "                # tiecov\n",
    "                tiecov_cmd = f\"tiecov -c {exp_cov_fname} -j {exp_junctions_fname} {exp_bam_fname}\"\n",
    "                tiecov_cmd_outFP.write(f\"{tiecov_cmd}\\n\")\n",
    "                # gffcompare\n",
    "                gffcmp_cmd = f\"gffcompare -r {reference_gtf_fname} -o {exp_gtf_fname} -i {exp_gtf_lst_fname}\"\n",
    "                gffcmp_cmd_outFP.write(f\"{gffcmp_cmd}\\n\")\n",
    "        # tb\n",
    "        tb_cmd = f\"tiebrush -o {all_bam_fname} {all_bam_lst_fname}\"\n",
    "        tb_cmd_outFP.write(f\"{tb_cmd}\\n\")\n",
    "        # tiecov\n",
    "        tiecov_cmd = f\"tiecov -c {all_cov_fname} -j {all_junctions_fname} {all_bam_fname}\"\n",
    "        tiecov_cmd_outFP.write(f\"{tiecov_cmd}\\n\")\n",
    "        # gffcompare\n",
    "        gffcmp_cmd = f\"gffcompare -r {reference_gtf_fname} -o {all_gtf_fname} -i {all_gtf_lst_fname}\"\n",
    "        gffcmp_cmd_outFP.write(f\"{gffcmp_cmd}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run gffcompare\n",
    "for grp_name, grp_data in cmp_groups.items():\n",
    "    all_name = \".\".join(grp_name)\n",
    "    all_gtf_lst_fname = prj_assembly_dir / f'{all_name}.lst'\n",
    "    with open(all_gtf_lst_fname, 'w') as all_gtf_outFP:\n",
    "        for exp_name, run_ids in grp_data.items():\n",
    "            exp_gtf_lst_fname = prj_assembly_dir / f'{exp_name}.lst'\n",
    "            \n",
    "            gffcmp_exp_gtf_fname = prj_assembly_dir / f'{exp_name}.combined.gtf'\n",
    "            gffcmp_exp_tracking_fname = prj_assembly_dir / f'{exp_name}.tracking'\n",
    "            \n",
    "            all_gtf_outFP.write(f\"{gffcmp_exp_gtf_fname}\\n\")\n",
    "            \n",
    "            with open(exp_gtf_lst_fname, 'w') as exp_gtf_outFP:\n",
    "                for run_id in run_ids:\n",
    "                    exp_gtf_outFP.write(f\"{prj_assembly_dir}/{run_id}.gtf\\n\")\n",
    "                    \n",
    "            definitions.run_gffcompare({\"-r\": reference_gtf_fname, \"-p\": f\"{exp_name}\", \"-o\": f\"{prj_assembly_dir}/{exp_name}\", \"-i\": exp_gtf_lst_fname})\n",
    "            \n",
    "            # subset\n",
    "            # load the tids with the the seqid\n",
    "            exp_gtf_df = definitions.get_attribute(gffcmp_exp_gtf_fname, [\"transcript_id\"],[0])\n",
    "            exp_tids = exp_gtf_df[exp_gtf_df[0]==hiv_accid][\"transcript_id\"].tolist()\n",
    "            # subset to the viral genome\n",
    "            # subset gtf\n",
    "            sub_gffcmp_exp_gtf_fname = prj_assembly_dir / f'{exp_name}.{hiv_accid}.gtf'\n",
    "            sub_gffcmp_exp_tracking_fname = prj_assembly_dir / f'{exp_name}.{hiv_accid}.tracking'\n",
    "            definitions.subset_gtf(gffcmp_exp_gtf_fname,sub_gffcmp_exp_gtf_fname,[],exp_tids)\n",
    "            definitions.subset_tracking(gffcmp_exp_tracking_fname,sub_gffcmp_exp_tracking_fname,exp_tids)\n",
    "            \n",
    "    definitions.run_gffcompare({\"-r\": reference_gtf_fname, \"-p\": f\"{all_name}\", \"-o\": f\"{prj_assembly_dir}/{all_name}\", \"-i\": all_gtf_lst_fname})\n",
    "    \n",
    "    # subset\n",
    "    gffcmp_all_gtf_fname = prj_assembly_dir / f'{all_name}.combined.gtf'\n",
    "    gffcmp_all_tracking_fname = prj_assembly_dir / f'{all_name}.tracking'\n",
    "    # load the tids with the the seqid\n",
    "    all_gtf_df = definitions.get_attribute(gffcmp_all_gtf_fname, [\"transcript_id\"],[0])\n",
    "    all_tids = all_gtf_df[all_gtf_df[0]==hiv_accid][\"transcript_id\"].tolist()\n",
    "    # subset to the viral genome\n",
    "    # subset gtf\n",
    "    sub_gffcmp_all_gtf_fname = prj_assembly_dir / f'{all_name}.{hiv_accid}.gtf'\n",
    "    sub_gffcmp_all_tracking_fname = prj_assembly_dir / f'{all_name}.{hiv_accid}.tracking'\n",
    "    definitions.subset_gtf(gffcmp_all_gtf_fname,sub_gffcmp_all_gtf_fname,[],all_tids)\n",
    "    definitions.subset_tracking(gffcmp_all_tracking_fname,sub_gffcmp_all_tracking_fname,all_tids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run orfanage on novel transcripts\n",
    "for grp_name, grp_data in cmp_groups.items():\n",
    "    all_name = \".\".join(grp_name)\n",
    "    for exp_name, run_ids in grp_data.items():\n",
    "        sub_gffcmp_exp_gtf_fname = prj_assembly_dir / f'{exp_name}.{hiv_accid}.gtf'\n",
    "        orf_exp_gtf_fname = prj_assembly_dir / f'{exp_name}.{hiv_accid}.orfanage.gtf'\n",
    "        cmd = f\"orfanage --query {sub_gffcmp_exp_gtf_fname} --reference {reference_fasta_fname} --output {orf_exp_gtf_fname} {reference_gtf_fname}\"\n",
    "        print(cmd)\n",
    "        subprocess.run(cmd, shell=True)\n",
    "\n",
    "    sub_gffcmp_all_gtf_fname = prj_assembly_dir / f'{all_name}.{hiv_accid}.gtf'\n",
    "    orf_all_gtf_fname = prj_assembly_dir / f'{all_name}.{hiv_accid}.orfanage.gtf'\n",
    "    cmd = f\"orfanage --query {sub_gffcmp_all_gtf_fname} --reference {reference_fasta_fname} --output {orf_all_gtf_fname} {reference_gtf_fname}\"\n",
    "    print(cmd)\n",
    "    subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each experiment - propagate expressions via tracking into the gtf\n",
    "for grp_name, grp_data in cmp_groups.items():\n",
    "    all_name = \".\".join(grp_name)\n",
    "    \n",
    "    sub_gffcmp_all_tracking_fname = prj_assembly_dir / f'{all_name}.{hiv_accid}.tracking'\n",
    "    hierarchy = {\n",
    "        (all_name,sub_gffcmp_all_tracking_fname):{}\n",
    "    }\n",
    "    \n",
    "    for exp_name, run_ids in grp_data.items():\n",
    "        sub_gffcmp_exp_tracking_fname = prj_assembly_dir / f'{exp_name}.{hiv_accid}.tracking'\n",
    "        hierarchy[(all_name,sub_gffcmp_all_tracking_fname)][(exp_name,sub_gffcmp_exp_tracking_fname)] = {}\n",
    "        \n",
    "    orf_all_gtf_fname = prj_assembly_dir / f'{all_name}.{hiv_accid}.orfanage.gtf'\n",
    "    augmented_orf_all_gtf_fname = prj_assembly_dir / f'{all_name}.{hiv_accid}.orfanage.tracking.gtf'\n",
    "    definitions.combine_tracking_gtf(orf_all_gtf_fname, hierarchy, augmented_orf_all_gtf_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing group: RiboSeq.RNASeq\n",
      "68 novel transcripts detected in the dataset: RiboSeq.RNASeq\n",
      "number of novel transcripts with >10% of samples in RiboSeq.RNASeq: 5\n"
     ]
    }
   ],
   "source": [
    "# load and process stringtie results\n",
    "strg_tdf = pd.DataFrame()\n",
    "def load_and_process_stringtie(gtf_fname, all_name, experiments, num_significant_transcripts, out_basename):\n",
    "    global strg_tdf\n",
    "    # experiments is a dict of name to number of samples\n",
    "    # load a table for each assembled transcript with the data\n",
    "    columns = [\"class_code\", f\"{all_name}_tpm_mean\", f\"{all_name}_num_samples\"] + \\\n",
    "              [f\"{exp_name}_tpm_mean\" for exp_name in experiments] + \\\n",
    "              [f\"{exp_name}_num_samples\" for exp_name in experiments]\n",
    "    exp_df = definitions.get_attribute(gtf_fname, columns)\n",
    "    \n",
    "    # Replace \"-\" with 0\n",
    "    exp_df.replace(\"-\", 0, inplace=True)\n",
    "    \n",
    "    # Convert to numeric\n",
    "    num_cols = exp_df.columns.difference(['tid', 'class_code'])\n",
    "    exp_df[num_cols] = exp_df[num_cols].astype(float)\n",
    "    exp_df.sort_values(by=f\"{all_name}_num_samples\", ascending=False, inplace=True)\n",
    "\n",
    "    # Compute percent samples\n",
    "    exp_df[f\"{all_name}_percent_samples\"] = exp_df[f\"{all_name}_num_samples\"] / metadata_df.shape[0]\n",
    "    for exp_name, run_ids in experiments.items():\n",
    "        exp_df[f\"{exp_name}_percent_samples\"] = exp_df[f\"{exp_name}_num_samples\"] / len(run_ids)\n",
    "\n",
    "    # Compute percentage sample difference for each experiment\n",
    "    for exp_name in experiments.keys():\n",
    "        # Sum percent_samples of all other experiments\n",
    "        other_exps_percent_samples = sum(\n",
    "            exp_df[f\"{other_exp}_percent_samples\"] \n",
    "            for other_exp in experiments.keys() if other_exp != exp_name\n",
    "        )\n",
    "        \n",
    "        # Compute absolute difference\n",
    "        exp_df[f\"{exp_name}_perc_samples_diff\"] = abs(\n",
    "            exp_df[f\"{exp_name}_percent_samples\"] - other_exps_percent_samples\n",
    "        )\n",
    "        \n",
    "        # Bin the percentage sample difference\n",
    "        exp_df[f\"{exp_name}_perc_samples_diff_bin\"] = pd.cut(\n",
    "            exp_df[f\"{exp_name}_perc_samples_diff\"], bins=10, labels=False\n",
    "        )\n",
    "\n",
    "    # isolate novel\n",
    "    novel_exp_df = exp_df[~(exp_df[\"class_code\"]==\"=\")].reset_index(drop=True)\n",
    "    # total number of novel transcripts\n",
    "    print(f\"{novel_exp_df.shape[0]} novel transcripts detected in the dataset: {all_name}\")\n",
    "\n",
    "    # create subsets of most promising novel transcripts\n",
    "    tids = novel_exp_df[novel_exp_df[f\"{all_name}_percent_samples\"]>0.1][\"tid\"].tolist()\n",
    "    print(f\"number of novel transcripts with >10% of samples in {all_name}: {len(tids)}\")\n",
    "    novel_gtf_fname = out_basename+\".top_novel_num_samples.gtf\"\n",
    "    definitions.subset_gtf(gtf_fname,novel_gtf_fname,[],tids)\n",
    "    \n",
    "    # save exp_df\n",
    "    exp_df.to_csv(out_basename+\".exp_df.tsv\",sep=\"\\t\",index=False)\n",
    "    \n",
    "    # use stringtie results to load up transcript quantifications \n",
    "    strg_tdf = pd.DataFrame()\n",
    "    for exp_name, run_ids in experiments.items():\n",
    "        for run_id in run_ids:\n",
    "            if not (prj_assembly_dir / f\"{run_id}.gtf\").exists():\n",
    "                continue\n",
    "        \n",
    "            tdf = definitions.get_chains(prj_assembly_dir / f\"{run_id}.gtf\",\"exon\",True)\n",
    "            tmp_df = definitions.get_attribute(prj_assembly_dir / f\"{run_id}.gtf\",[\"TPM\",\"reference_id\"])\n",
    "            tdf = tdf.merge(tmp_df,on=\"tid\")\n",
    "            tdf[\"run_accession\"] = run_id\n",
    "            tdf[\"sample\"] = exp_name\n",
    "            strg_tdf = pd.concat([strg_tdf, tdf])\n",
    "\n",
    "    strg_tdf = strg_tdf[(strg_tdf[\"seqid\"]==hiv_accid)].reset_index(drop=True)\n",
    "    strg_tdf[\"TPM\"] = pd.to_numeric(strg_tdf[\"TPM\"], errors='coerce')\n",
    "    strg_tdf.to_csv(out_basename + \".transcript_tpm.tsv\",sep=\"\\t\",index=False)\n",
    "    \n",
    "    # Pivot table for statistical analysis\n",
    "    pivot_df = strg_tdf.pivot_table(index='reference_id', columns=['sample',\"run_accession\"], values='TPM')\n",
    "    # Perform ANOVA to identify significant transcripts\n",
    "    anova_results = []\n",
    "    for tid, row in pivot_df.iterrows():\n",
    "        groups = [row.filter(like=exp).dropna() for exp in experiments.keys()]\n",
    "        \n",
    "        # Ensure each group has more than one value (replicates)\n",
    "        if all(len(group) > 1 for group in groups):\n",
    "            stat, pval = f_oneway(*groups)  # Perform ANOVA\n",
    "            anova_results.append((tid, pval))\n",
    "\n",
    "    anova_df = pd.DataFrame(anova_results, columns=['reference_id', 'pval'])\n",
    "    anova_df['significant'] = anova_df['pval'] < 0.05\n",
    "\n",
    "    print(f\"Number of significant transcripts: {anova_df['significant'].sum()}\")\n",
    "    anova_df.to_csv(out_basename + \".anova.tsv\",sep=\"\\t\",index=False)\n",
    "    \n",
    "    significant_tids = anova_df[anova_df['significant']]['reference_id'].tolist()\n",
    "    top_transcripts = significant_tids[:num_significant_transcripts]\n",
    "\n",
    "    # setup the figure of split violin plots for significant tids\n",
    "    fig, axes = plt.subplots(1, num_significant_transcripts, figsize=(4*num_significant_transcripts, 6), sharey=False)\n",
    "    for i, tid in enumerate(top_transcripts):\n",
    "        transcript_data = strg_tdf[strg_tdf['reference_id'] == tid]\n",
    "        ax = axes[i] if num_significant_transcripts > 1 else axes\n",
    "        sns.violinplot(\n",
    "            data=transcript_data,\n",
    "            x='reference_id',\n",
    "            y='TPM',\n",
    "            hue='sample',\n",
    "            split=True,\n",
    "            inner='quart',\n",
    "            fill=False,\n",
    "            ax=ax\n",
    "        )\n",
    "        \n",
    "        ax.set_title(f\"{tid}\")\n",
    "        ax.set_xlabel(\"\") \n",
    "        if i > 0:\n",
    "            ax.set_ylabel(\"\")\n",
    "        if i < num_significant_transcripts - 1:\n",
    "            ax.get_legend().remove()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_basename + \".violin_plot.png\")\n",
    "    \n",
    "    # write a list of tiecov coverage and junction files and names of monkeys for the cov/sj/tn params of sashimi\n",
    "    cov_lst_fname = out_basename + '.cov_lst.txt'\n",
    "    with open(cov_lst_fname, 'w') as outFP:\n",
    "        for exp_name, run_ids in experiments.items():\n",
    "            outFP.write(f\"{prj_aln_dir}/{exp_name}.{hiv_accid}.coverage.bedgraph\\n\")\n",
    "    sj_lst_fname = out_basename + '.sj_lst.txt'\n",
    "    with open(sj_lst_fname, 'w') as outFP:\n",
    "        for exp_name, run_ids in experiments.items():\n",
    "            outFP.write(f\"{prj_aln_dir}/{exp_name}.{hiv_accid}.junctions.bed\\n\")\n",
    "    tn_lst_fname = out_basename + '.tn_lst.txt'\n",
    "    with open(tn_lst_fname, 'w') as outFP:\n",
    "        for exp_name, run_ids in experiments.items():\n",
    "            outFP.write(f\"{exp_name}\\n\")\n",
    "            \n",
    "    # build sashimi plots for the significant transcripts\n",
    "    # we want to compare tiebrush between T034 and Ay69 for a given transcript only\n",
    "\n",
    "    viral_tids = [x for x in strg_tdf['reference_id'].tolist() if x != \"-\"]\n",
    "    viral_gtf_fname = out_basename + '.viral.gtf'\n",
    "    definitions.subset_gtf(reference_gtf_fname,viral_gtf_fname,[],viral_tids)\n",
    "    # build for entire transcriptome\n",
    "    sashimi_svg_fname = out_basename + '.svg'\n",
    "    sashimi_cmd = [sashimi_bin,\n",
    "                    \"--title\",tid,\n",
    "                    \"--gtf\",str(viral_gtf_fname),\n",
    "                    \"-o\",str(sashimi_svg_fname),\n",
    "                    \"--normalize\",\n",
    "                    \"--subtract\",\"0\",\n",
    "                    \"--intron_scale\",\"1\",\n",
    "                    \"--exon_scale\",\"1\",\n",
    "                    \"--tn\",str(tn_lst_fname),\n",
    "                    \"--cov\",str(cov_lst_fname),\n",
    "                    \"--sj\",str(sj_lst_fname)]\n",
    "    subprocess.call(sashimi_cmd)\n",
    "\n",
    "    # SASHIMI WITHOUT NORMALIZATION\n",
    "    sashimi_svg_fname = out_basename + '.non_normalized.svg'\n",
    "\n",
    "    sashimi_cmd = [sashimi_bin,\n",
    "                    \"--title\",tid,\n",
    "                    \"--gtf\",str(viral_gtf_fname),\n",
    "                    \"-o\",str(sashimi_svg_fname),\n",
    "                    \"--intron_scale\",\"1\",\n",
    "                    \"--exon_scale\",\"1\",\n",
    "                    \"--tn\",str(tn_lst_fname),\n",
    "                    \"--cov\",str(cov_lst_fname),\n",
    "                    \"--sj\",str(sj_lst_fname),\n",
    "                    \"--subtract\",\"0\"]\n",
    "    subprocess.call(sashimi_cmd)\n",
    "\n",
    "    # now build transcript-specific plots\n",
    "    for tid in set(strg_tdf['reference_id'].tolist()):\n",
    "        if tid == \"-\": # skip non-reference transcripts\n",
    "            continue\n",
    "        try:\n",
    "            tx_gtf_fname = out_basename + f'.{tid}.gtf'\n",
    "            tx_svg_fname = out_basename + f'.{tid}.svg'\n",
    "\n",
    "            # extract the transcript from the gtf\n",
    "            definitions.subset_gtf(reference_gtf_fname,tx_gtf_fname,False,[tid])\n",
    "\n",
    "            # build sashimi plot\n",
    "            sashimi_cmd = [sashimi_bin,\n",
    "                            \"--title\",tid,\n",
    "                            \"--gtf\",str(tx_gtf_fname),\n",
    "                            \"-o\",str(tx_svg_fname),\n",
    "                            \"--normalize\",\n",
    "                            \"--subtract\",\"0\",\n",
    "                            \"--intron_scale\",\"1\",\n",
    "                            \"--exon_scale\",\"1\",\n",
    "                            \"--tn\",str(tn_lst_fname),\n",
    "                            \"--cov\",str(cov_lst_fname),\n",
    "                            \"--sj\",str(sj_lst_fname)]\n",
    "            subprocess.call(sashimi_cmd)\n",
    "\n",
    "            # SASHIMI WITHOUT NORMALIZATION\n",
    "            tx_svg_fname = out_basename + f'{tid}.non_normalized.svg'\n",
    "\n",
    "            sashimi_cmd = [sashimi_bin,\n",
    "                            \"--title\",tid,\n",
    "                            \"--gtf\",str(tx_gtf_fname),\n",
    "                            \"-o\",str(tx_svg_fname),\n",
    "                            \"--intron_scale\",\"1\",\n",
    "                            \"--exon_scale\",\"1\",\n",
    "                            \"--tn\",str(tn_lst_fname),\n",
    "                            \"--cov\",str(cov_lst_fname),\n",
    "                            \"--sj\",str(sj_lst_fname),\n",
    "                            \"--subtract\",\"0\"]\n",
    "            subprocess.call(sashimi_cmd)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {tid}: {e}\")\n",
    "            continue\n",
    "\n",
    "    \n",
    "for grp_name, grp_data in cmp_groups.items():\n",
    "    all_name = \".\".join(grp_name)\n",
    "    print(f\"Processing group: {all_name}\")\n",
    "    \n",
    "    out_all_name_dir = prj_quant_dir / all_name\n",
    "    out_all_name_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    gtf_fname = prj_assembly_dir / f'{all_name}.{hiv_accid}.orfanage.tracking.gtf'\n",
    "    out_basename = str(out_all_name_dir / f'{all_name}.{hiv_accid}.orfanage.tracking')\n",
    "    experiments = {exp_name: run_ids for exp_name, run_ids in grp_data.items()}\n",
    "    load_and_process_stringtie(gtf_fname, all_name, experiments, 5, out_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hivAtlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
